diff --git a/llamia_v3_2/graph.py b/llamia_v3_2/graph.py
index 286765a1a1e7524e97f3eac0b347d7613a8a1034..b5915bb567e30ad74a9ed80617a1e6f1ec7fc3c8 100644
--- a/llamia_v3_2/graph.py
+++ b/llamia_v3_2/graph.py
@@ -1,33 +1,34 @@
 from __future__ import annotations
 
 import json
 from typing import Any, Callable
 
 from langgraph.graph import StateGraph, END
 
 from .state import LlamiaGraphState
+from .nodes.intent_classifier import intent_classifier_node
 from .nodes.intent_router import intent_router_node
 from .nodes.chat import chat_node
 from .nodes.planner import planner_node
 from .nodes.coder import coder_node
 from .nodes.executor import executor_node
 from .nodes.research import research_node
 from .nodes.critic import critic_node
 from .nodes.research_web import research_web_node
 
 
 # -----------------------------
 # Trace helpers (trace is list[str] in state.py)
 # -----------------------------
 def _get_attr(state: Any, name: str, default: Any = None) -> Any:
     if hasattr(state, name):
         return getattr(state, name)
     if isinstance(state, dict):
         return state.get(name, default)
     return default
 
 
 def _safe_head(s: Any, n: int = 220) -> str:
     txt = str(s or "")
     return txt[:n].replace("\n", "\\n")
 
@@ -118,172 +119,172 @@ def _wrap_step(
         return out
 
     return _step
 
 
 def _wrap_router(name: str, router_fn: Callable[[Any], str]) -> Callable[[Any], str]:
     def _r(state: Any) -> str:
         choice = router_fn(state)
         _trace(state, {"event": "route", "node": name, "choice": choice, "snap": _snapshot(state)})
         return choice
 
     return _r
 
 
 # -----------------------------
 # Routing helpers
 # -----------------------------
 def _get_mode_and_goal(state: Any) -> tuple[str, str | None]:
     if hasattr(state, "mode"):
         return getattr(state, "mode"), getattr(state, "goal", None)
     if isinstance(state, dict):
         return state.get("mode", "chat"), state.get("goal")
     return "chat", None
 
 
-def _latest_user_text(state: Any) -> str:
-    msgs = _get_attr(state, "messages", []) or []
-    if not isinstance(msgs, list):
-        return ""
-    for m in reversed(msgs):
-        if isinstance(m, dict) and m.get("role") == "user":
-            return str(m.get("content", "")).strip()
-    return ""
-
-
-def _looks_like_research(user_text: str) -> bool:
-    t = user_text.lower().strip()
-    if t.startswith("research:") or t.startswith("reindex:"):
-        return True
-    keywords = ["workspace", "repo", "repository", "project files", "codebase", "in this folder"]
-    intents = ["what files", "list files", "show files", "summarize files", "what does this do", "explain this project"]
-    return any(k in t for k in keywords) and any(i in t for i in intents)
-
-
 def _route_from_intent(state: Any) -> str:
     nxt = _get_attr(state, "next_agent", None)
     allowed = {"chat", "planner", "research", "research_web"}
     if isinstance(nxt, str) and nxt in allowed:
         return nxt
 
-    user_text = _latest_user_text(state)
-    if _looks_like_research(user_text):
-        return "research"
+    intent = _get_attr(state, "intent_kind", None)
+    if isinstance(intent, str) and intent in allowed:
+        return intent
 
     mode, goal = _get_mode_and_goal(state)
     if mode == "task" and goal:
         return "planner"
 
     return "chat"
 
 
 def _route_from_planner(state: Any) -> str:
     # Honor explicit next_agent set by planner_node (or upstream fix-instructions)
     nxt = _get_attr(state, "next_agent", None)
     if isinstance(nxt, str) and nxt in {"research_web", "research"}:
         return nxt
 
     # Optional heuristic: patch/diff tasks often benefit from repo context
     goal = str(_get_attr(state, "goal", "") or "").lower()
     if ("diff" in goal or "patch" in goal or "improvements.patch" in goal) and not _get_attr(state, "research_notes", None):
         return "research"
 
     return "coder"
 
 
 def _route_from_research(state: Any) -> str:
+    nxt = _get_attr(state, "next_agent", None)
+    allowed = {"planner", "coder", "chat", "research"}
+    if isinstance(nxt, str) and nxt in allowed:
+        return nxt
+
+    return_after = _get_attr(state, "return_after_research", None)
+    if isinstance(return_after, str) and return_after in allowed:
+        return return_after
+
     mode, goal = _get_mode_and_goal(state)
     if mode == "task" and goal:
         return "planner"
     return "chat"
 
 
 def _route_from_research_web(state: Any) -> str:
+    nxt = _get_attr(state, "next_agent", None)
+    allowed = {"coder", "planner", "chat", "research_web"}
+    if isinstance(nxt, str) and nxt in allowed:
+        return nxt
+
+    return_after = _get_attr(state, "return_after_web", None)
+    if isinstance(return_after, str) and return_after in allowed:
+        return return_after
+
     mode, goal = _get_mode_and_goal(state)
     if mode != "task" or not goal:
         return "chat"
 
     plan = _get_attr(state, "plan", []) or []
     if isinstance(plan, list) and len(plan) == 0:
         return "planner"
     return "coder"
 
 
 def _route_from_coder(state: Any) -> str:
     # Honor coder's request first (retry loops or research handoff)
     nxt = _get_attr(state, "next_agent", None)
     if isinstance(nxt, str) and nxt in {"coder", "research", "research_web"}:
         return nxt
     return "executor"
 
 
 def _route_from_critic(state: Any) -> str:
     nxt = _get_attr(state, "next_agent", None)
     allowed = {"chat", "planner", "coder", "research", "research_web"}
     if isinstance(nxt, str) and nxt in allowed:
         return nxt
     return "chat"
 
 
 def build_llamia_graph():
     workflow = StateGraph(LlamiaGraphState)
 
     # Wrap nodes (enter/exit)
+    workflow.add_node("intent_classifier", _wrap_step("intent_classifier", intent_classifier_node))
     workflow.add_node("intent_router", _wrap_step("intent_router", intent_router_node))
     workflow.add_node("research", _wrap_step("research", research_node))
     workflow.add_node("research_web", _wrap_step("research_web", research_web_node))
     workflow.add_node("planner", _wrap_step("planner", planner_node))
     workflow.add_node("coder", _wrap_step("coder", coder_node))
     workflow.add_node("executor", _wrap_step("executor", executor_node))
     workflow.add_node("critic", _wrap_step("critic", critic_node))
     workflow.add_node("chat", _wrap_step("chat", chat_node))
 
-    workflow.set_entry_point("intent_router")
+    workflow.set_entry_point("intent_classifier")
+    workflow.add_edge("intent_classifier", "intent_router")
 
     # intent_router -> {research_web, research, planner, chat}
     workflow.add_conditional_edges(
         "intent_router",
         _wrap_router("intent_router", _route_from_intent),
         {"research_web": "research_web", "research": "research", "planner": "planner", "chat": "chat"},
     )
 
-    # research -> {planner, chat}
+    # research -> {planner, coder, research, chat}
     workflow.add_conditional_edges(
         "research",
         _wrap_router("research", _route_from_research),
-        {"planner": "planner", "chat": "chat"},
+        {"planner": "planner", "coder": "coder", "research": "research", "chat": "chat"},
     )
 
-    # research_web -> {coder, planner, chat}
+    # research_web -> {coder, planner, research_web, chat}
     workflow.add_conditional_edges(
         "research_web",
         _wrap_router("research_web", _route_from_research_web),
-        {"coder": "coder", "planner": "planner", "chat": "chat"},
+        {"coder": "coder", "planner": "planner", "research_web": "research_web", "chat": "chat"},
     )
 
     # planner -> {research_web, research, coder}  (FIXED: include research)
     workflow.add_conditional_edges(
         "planner",
         _wrap_router("planner", _route_from_planner),
         {"research_web": "research_web", "research": "research", "coder": "coder"},
     )
 
     # coder -> {coder, research, research_web, executor}
     workflow.add_conditional_edges(
         "coder",
         _wrap_router("coder", _route_from_coder),
         {"coder": "coder", "research": "research", "research_web": "research_web", "executor": "executor"},
     )
 
     # executor -> critic
     workflow.add_edge("executor", "critic")
 
     # critic -> {coder, planner, research, research_web, chat}
     workflow.add_conditional_edges(
         "critic",
         _wrap_router("critic", _route_from_critic),
         {"coder": "coder", "planner": "planner", "research": "research", "research_web": "research_web", "chat": "chat"},
     )
 
     workflow.add_edge("chat", END)
     return workflow.compile()
-
diff --git a/llamia_v3_2/graph_improved.py b/llamia_v3_2/graph_improved.py
index 4919856d47ca9908b45654be4ab0b7098a4a84f8..1a09c5e5e0f6efaf68a7cebcfefc6cc6f16d763f 100644
--- a/llamia_v3_2/graph_improved.py
+++ b/llamia_v3_2/graph_improved.py
@@ -1,34 +1,35 @@
 from __future__ import annotations
 
 import json
 import logging
 from typing import Any, Callable
 
 from langgraph.graph import StateGraph, END
 
 from .state import LlamiaGraphState
+from .nodes.intent_classifier import intent_classifier_node
 from .nodes.intent_router import intent_router_node
 from .nodes.chat import chat_node
 from .nodes.planner import planner_node
 from .nodes.coder import coder_node
 from .nodes.executor import executor_node
 from .nodes.research import research_node
 from .nodes.critic import critic_node
 from .nodes.research_web import research_web_node
 
 # Set up logging
 logger = logging.getLogger(__name__)
 
 # -----------------------------
 # Trace helpers (trace is list[str] in state.py)
 # -----------------------------
 def _get_attr(state: Any, name: str, default: Any = None) -> Any:
     if hasattr(state, name):
         return getattr(state, name)
     if isinstance(state, dict):
         return state.get(name, default)
     return default
 
 
 def _safe_head(s: Any, n: int = 220) -> str:
     txt = str(s or "")
@@ -132,195 +133,191 @@ def _wrap_router(name: str, router_fn: Callable[[Any], str]) -> Callable[[Any],
             return choice
         except Exception as e:
             logger.error(f"Error in router {name}: {e}")
             # Default to chat node on error
             _trace(state, {"event": "route_error", "node": name, "error": str(e), "choice": "chat"})
             return "chat"
 
     return _r
 
 
 # -----------------------------
 # Routing helpers
 # -----------------------------
 def _get_mode_and_goal(state: Any) -> tuple[str, str | None]:
     try:
         if hasattr(state, "mode"):
             return getattr(state, "mode"), getattr(state, "goal", None)
         if isinstance(state, dict):
             return state.get("mode", "chat"), state.get("goal")
         return "chat", None
     except Exception as e:
         logger.error(f"Error in _get_mode_and_goal: {e}")
         return "chat", None
 
 
-def _latest_user_text(state: Any) -> str:
-    try:
-        msgs = _get_attr(state, "messages", []) or []
-        if not isinstance(msgs, list):
-            return ""
-        for m in reversed(msgs):
-            if isinstance(m, dict) and m.get("role") == "user":
-                return str(m.get("content", "")).strip()
-        return ""
-    except Exception as e:
-        logger.error(f"Error in _latest_user_text: {e}")
-        return ""
-
-
-def _looks_like_research(user_text: str) -> bool:
-    try:
-        t = user_text.lower().strip()
-        if t.startswith("research:") or t.startswith("reindex:"):
-            return True
-        keywords = ["workspace", "repo", "repository", "project files", "codebase", "in this folder"]
-        intents = ["what files", "list files", "show files", "summarize files", "what does this do", "explain this project"]
-        return any(k in t for k in keywords) and any(i in t for i in intents)
-    except Exception as e:
-        logger.error(f"Error in _looks_like_research: {e}")
-        return False
-
-
 def _route_from_intent(state: Any) -> str:
     try:
         nxt = _get_attr(state, "next_agent", None)
         allowed = {"chat", "planner", "research", "research_web"}
         if isinstance(nxt, str) and nxt in allowed:
             return nxt
 
-        user_text = _latest_user_text(state)
-        if _looks_like_research(user_text):
-            return "research"
+        intent = _get_attr(state, "intent_kind", None)
+        if isinstance(intent, str) and intent in allowed:
+            return intent
 
         mode, goal = _get_mode_and_goal(state)
         if mode == "task" and goal:
             return "planner"
 
         return "chat"
     except Exception as e:
         logger.error(f"Error in _route_from_intent: {e}")
         return "chat"
 
 
 def _route_from_planner(state: Any) -> str:
     try:
         # Honor explicit next_agent set by planner_node (or upstream fix-instructions)
         nxt = _get_attr(state, "next_agent", None)
         if isinstance(nxt, str) and nxt in {"research_web", "research"}:
             return nxt
 
         # Optional heuristic: patch/diff tasks often benefit from repo context
         goal = str(_get_attr(state, "goal", "") or "").lower()
         if ("diff" in goal or "patch" in goal or "improvements.patch" in goal) and not _get_attr(state, "research_notes", None):
             return "research"
 
         return "coder"
     except Exception as e:
         logger.error(f"Error in _route_from_planner: {e}")
         return "coder"
 
 
 def _route_from_research(state: Any) -> str:
     try:
+        nxt = _get_attr(state, "next_agent", None)
+        allowed = {"planner", "coder", "chat", "research"}
+        if isinstance(nxt, str) and nxt in allowed:
+            return nxt
+
+        return_after = _get_attr(state, "return_after_research", None)
+        if isinstance(return_after, str) and return_after in allowed:
+            return return_after
+
         mode, goal = _get_mode_and_goal(state)
         if mode == "task" and goal:
             return "planner"
         return "chat"
     except Exception as e:
         logger.error(f"Error in _route_from_research: {e}")
         return "chat"
 
 
 def _route_from_research_web(state: Any) -> str:
     try:
         nxt = _get_attr(state, "next_agent", None)
-        if isinstance(nxt, str) and nxt in {"coder", "planner", "research", "research_web"}:
+        if isinstance(nxt, str) and nxt in {"coder", "planner", "chat", "research_web"}:
             return nxt
-        return "executor"
+
+        return_after = _get_attr(state, "return_after_web", None)
+        if isinstance(return_after, str) and return_after in {"coder", "planner", "chat", "research_web"}:
+            return return_after
+
+        mode, goal = _get_mode_and_goal(state)
+        if mode != "task" or not goal:
+            return "chat"
+
+        plan = _get_attr(state, "plan", []) or []
+        if isinstance(plan, list) and len(plan) == 0:
+            return "planner"
+        return "coder"
     except Exception as e:
         logger.error(f"Error in _route_from_research_web: {e}")
-        return "executor"
+        return "chat"
 
 
 def _route_from_coder(state: Any) -> str:
     try:
         nxt = _get_attr(state, "next_agent", None)
         if isinstance(nxt, str) and nxt in {"coder", "research", "research_web", "executor"}:
             return nxt
         return "executor"
     except Exception as e:
         logger.error(f"Error in _route_from_coder: {e}")
         return "executor"
 
 
 def _route_from_critic(state: Any) -> str:
     try:
         nxt = _get_attr(state, "next_agent", None)
         allowed = {"chat", "planner", "coder", "research", "research_web"}
         if isinstance(nxt, str) and nxt in allowed:
             return nxt
         return "chat"
     except Exception as e:
         logger.error(f"Error in _route_from_critic: {e}")
         return "chat"
 
 
 def build_llamia_graph():
     workflow = StateGraph(LlamiaGraphState)
 
     # Wrap nodes (enter/exit)
+    workflow.add_node("intent_classifier", _wrap_step("intent_classifier", intent_classifier_node))
     workflow.add_node("intent_router", _wrap_step("intent_router", intent_router_node))
     workflow.add_node("research", _wrap_step("research", research_node))
     workflow.add_node("research_web", _wrap_step("research_web", research_web_node))
     workflow.add_node("planner", _wrap_step("planner", planner_node))
     workflow.add_node("coder", _wrap_step("coder", coder_node))
     workflow.add_node("executor", _wrap_step("executor", executor_node))
     workflow.add_node("critic", _wrap_step("critic", critic_node))
     workflow.add_node("chat", _wrap_step("chat", chat_node))
 
-    workflow.set_entry_point("intent_router")
+    workflow.set_entry_point("intent_classifier")
+    workflow.add_edge("intent_classifier", "intent_router")
 
     # intent_router -> {research_web, research, planner, chat}
     workflow.add_conditional_edges(
         "intent_router",
         _wrap_router("intent_router", _route_from_intent),
         {"research_web": "research_web", "research": "research", "planner": "planner", "chat": "chat"},
     )
 
-    # research -> {planner, chat}
+    # research -> {planner, coder, research, chat}
     workflow.add_conditional_edges(
         "research",
         _wrap_router("research", _route_from_research),
-        {"planner": "planner", "chat": "chat"},
+        {"planner": "planner", "coder": "coder", "research": "research", "chat": "chat"},
     )
 
-    # research_web -> {coder, planner, chat}
+    # research_web -> {coder, planner, research_web, chat}
     workflow.add_conditional_edges(
         "research_web",
         _wrap_router("research_web", _route_from_research_web),
-        {"coder": "coder", "planner": "planner", "chat": "chat"},
+        {"coder": "coder", "planner": "planner", "research_web": "research_web", "chat": "chat"},
     )
 
     # planner -> {research_web, research, coder}  (FIXED: include research)
     workflow.add_conditional_edges(
         "planner",
         _wrap_router("planner", _route_from_planner),
         {"research_web": "research_web", "research": "research", "coder": "coder"},
     )
 
     # coder -> {coder, research, research_web, executor}
     workflow.add_conditional_edges(
         "coder",
         _wrap_router("coder", _route_from_coder),
         {"coder": "coder", "research": "research", "research_web": "research_web", "executor": "executor"},
     )
 
     # executor -> critic
     workflow.add_edge("executor", "critic")
 
     # critic -> {coder, planner, research, research_web, chat}
     workflow.add_conditional_edges(
         "critic",
         _wrap_router("critic", _route_from_critic),
         {"coder": "coder", "planner": "planner", "research": "research", "research_web": "research_web", "chat": "chat"},
     )
diff --git a/llamia_v3_2/nodes/critic.py b/llamia_v3_2/nodes/critic.py
index f32aa11b31427939df3d541c9b0127d7aeffcaab..62c2e7d9be5c092d89d92a584532b25b8c2cff43 100644
--- a/llamia_v3_2/nodes/critic.py
+++ b/llamia_v3_2/nodes/critic.py
@@ -141,58 +141,58 @@ def critic_node(state: LlamiaState) -> LlamiaState:
 
         needs_web = (
             DEFAULT_CONFIG.web_search_provider == "searxng"
             and _looks_like_needs_web(goal_text, stderr)
         )
 
         # Avoid spamming web searches
         web_count = int(getattr(state, "web_search_count", 0) or 0)
         max_web = 1  # keep it conservative; bump later if you want
         if needs_web and web_count < max_web:
             setattr(state, "web_search_count", web_count + 1)
             state.loop_count += 1
 
             q = _build_web_query(goal_text, last)
             state.research_query = q
 
             # Preserve fix instructions so coder can use web notes after research_web runs
             state.fix_instructions = (
                 "Execution failed and may require external info.\n"
                 "Use the web_search notes (research_notes) to apply the minimal fix needed so the command passes.\n\n"
                 f"Failed command: {last.command}\n"
                 f"Return code: {last.returncode}\n\n"
                 f"Stderr (tail):\n{tail}\n"
             )
 
+            state.return_after_web = "coder"
             state.next_agent = "research_web"
             state.add_message(
                 "system",
                 f"[critic] execution failed -> route to research_web (loop={state.loop_count}, web_count={web_count+1})",
                 node=NODE_NAME,
             )
             state.log(f"[{NODE_NAME}] done (route research_web)")
             return state
 
         # Normal fix path (no web)
         state.loop_count += 1
         state.fix_instructions = (
             "Execution failed. Apply the minimal fix needed so the command passes.\n\n"
             f"Failed command: {last.command}\n"
             f"Return code: {last.returncode}\n\n"
             f"Stderr (tail):\n{tail}\n"
         )
         state.next_agent = "coder"
         state.add_message(
             "system",
             f"[critic] execution failed -> route to coder (loop={state.loop_count})",
             node=NODE_NAME,
         )
         state.log(f"[{NODE_NAME}] done (route coder)")
         return state
 
     # success
     state.fix_instructions = None
     state.next_agent = "chat"
     state.add_message("system", "[critic] execution ok -> finishing", node=NODE_NAME)
     state.log(f"[{NODE_NAME}] done (success)")
     return state
-
diff --git a/llamia_v3_2/nodes/intent_classifier.py b/llamia_v3_2/nodes/intent_classifier.py
new file mode 100644
index 0000000000000000000000000000000000000000..86024b80f95a2d655d412e70481e4516830f2e50
--- /dev/null
+++ b/llamia_v3_2/nodes/intent_classifier.py
@@ -0,0 +1,156 @@
+from __future__ import annotations
+
+from ..state import LlamiaState
+
+NODE_NAME = "intent_classifier"
+
+
+def _strip_repl_prefix(text: str) -> str:
+    """
+    Users sometimes paste prompts like: 'you> task: ...'
+    Strip any leading 'you>' tokens so routing behaves consistently.
+    """
+    s = (text or "").strip()
+    while s.lower().startswith("you>"):
+        s = s[4:].lstrip()
+    return s
+
+
+def _extract_task_goal(raw: str) -> str:
+    text = _strip_repl_prefix(raw).strip()
+    lower = text.lower()
+    if lower.startswith("task:"):
+        return text[5:].strip() or "(unspecified task goal)"
+    if lower.startswith("task "):
+        return text[5:].strip() or "(unspecified task goal)"
+    return text
+
+
+def _looks_like_task(raw: str) -> bool:
+    lower = _strip_repl_prefix(raw).strip().lower()
+
+    if lower in {"hi", "hey", "hello", "yo", "sup"}:
+        return False
+
+    verb_keywords = [
+        "write a ",
+        "write an ",
+        "write the ",
+        "write some code",
+        "write code",
+        "write a script",
+        "build a ",
+        "build an ",
+        "build the ",
+        "create a ",
+        "create an ",
+        "generate code",
+        "implement ",
+        "make a script",
+        "make a program",
+        "fix this code",
+        "fix the code",
+        "refactor this",
+    ]
+
+    object_keywords = [
+        "script",
+        "program",
+        "function",
+        "module",
+        "tool",
+        "bot",
+        "cli",
+        "python script",
+        "python program",
+    ]
+
+    if any(kw in lower for kw in verb_keywords):
+        return True
+
+    if "python" in lower and any(obj in lower for obj in object_keywords):
+        return True
+
+    return False
+
+
+def _looks_like_web_search(text: str) -> bool:
+    t = _strip_repl_prefix(text).strip().lower()
+    return t.startswith("web:") or t.startswith("search:")
+
+
+def _extract_web_query(text: str) -> str:
+    t = _strip_repl_prefix(text).strip()
+    lower = t.lower()
+    if lower.startswith("web:"):
+        return t.split(":", 1)[1].strip()
+    if lower.startswith("search:"):
+        return t.split(":", 1)[1].strip()
+    return t
+
+
+def _looks_like_repo_research(text: str) -> bool:
+    t = _strip_repl_prefix(text).strip().lower()
+    return t.startswith("research:") or t.startswith("reindex:")
+
+
+def _extract_repo_research_query(text: str) -> str:
+    # Keep the prefix for research_node to parse reindex:/research:
+    return _strip_repl_prefix(text).strip()
+
+
+def intent_classifier_node(state: LlamiaState) -> LlamiaState:
+    state.log(f"[{NODE_NAME}] starting")
+
+    if not getattr(state, "messages", None):
+        state.intent_kind = "chat"
+        state.intent_payload = None
+        state.intent_source = "empty"
+        state.log(f"[{NODE_NAME}] no messages -> intent=chat")
+        return state
+
+    last = state.messages[-1]
+    if not isinstance(last, dict) or last.get("role") != "user":
+        state.intent_kind = None
+        state.intent_payload = None
+        state.intent_source = "non_user"
+        state.log(f"[{NODE_NAME}] last not user -> intent unchanged")
+        return state
+
+    text = _strip_repl_prefix(str(last.get("content", "") or ""))
+    lower = text.lower().strip()
+
+    if _looks_like_web_search(text):
+        state.intent_kind = "research_web"
+        state.intent_payload = _extract_web_query(text)
+        state.intent_source = "explicit_web"
+        state.log(f"[{NODE_NAME}] intent=research_web payload={state.intent_payload!r}")
+        return state
+
+    if _looks_like_repo_research(text):
+        state.intent_kind = "research"
+        state.intent_payload = _extract_repo_research_query(text)
+        state.intent_source = "explicit_research"
+        state.log(f"[{NODE_NAME}] intent=research payload={state.intent_payload!r}")
+        return state
+
+    if lower.startswith("task:") or lower.startswith("task "):
+        goal = _extract_task_goal(text)
+        state.intent_kind = "task"
+        state.intent_payload = goal
+        state.intent_source = "explicit_task"
+        state.log(f"[{NODE_NAME}] intent=task goal={goal!r}")
+        return state
+
+    if _looks_like_task(text):
+        state.intent_kind = "task"
+        state.intent_payload = text
+        state.intent_source = "heuristic_task"
+        state.log(f"[{NODE_NAME}] intent=task (heuristic)")
+        return state
+
+    state.intent_kind = "chat"
+    state.intent_payload = None
+    state.intent_source = "default_chat"
+    state.log(f"[{NODE_NAME}] intent=chat")
+    return state
diff --git a/llamia_v3_2/nodes/intent_router.py b/llamia_v3_2/nodes/intent_router.py
index f1556f297550ec9c085a8180c395dd4e3ee9212c..39200eb71f54392c33a77a7cb9d45997e15ef168 100644
--- a/llamia_v3_2/nodes/intent_router.py
+++ b/llamia_v3_2/nodes/intent_router.py
@@ -1,243 +1,151 @@
 from __future__ import annotations
 
 import time
 from typing import Any
 
 from ..state import LlamiaState
 
 NODE_NAME = "intent_router"
 
 
-def _strip_repl_prefix(text: str) -> str:
-    """
-    Users sometimes paste prompts like: 'you> task: ...'
-    Strip any leading 'you>' tokens so routing behaves consistently.
-    """
-    s = (text or "").strip()
-    while s.lower().startswith("you>"):
-        s = s[4:].lstrip()
-    return s
-
-
-def _extract_task_goal(raw: str) -> str:
-    text = _strip_repl_prefix(raw).strip()
-    lower = text.lower()
-    if lower.startswith("task:"):
-        return text[5:].strip() or "(unspecified task goal)"
-    if lower.startswith("task "):
-        return text[5:].strip() or "(unspecified task goal)"
-    return text
-
-
-def _looks_like_task(raw: str) -> bool:
-    lower = _strip_repl_prefix(raw).strip().lower()
-
-    if lower in {"hi", "hey", "hello", "yo", "sup"}:
-        return False
-
-    verb_keywords = [
-        "write a ",
-        "write an ",
-        "write the ",
-        "write some code",
-        "write code",
-        "write a script",
-        "build a ",
-        "build an ",
-        "build the ",
-        "create a ",
-        "create an ",
-        "generate code",
-        "implement ",
-        "make a script",
-        "make a program",
-        "fix this code",
-        "fix the code",
-        "refactor this",
-    ]
-
-    object_keywords = [
-        "script",
-        "program",
-        "function",
-        "module",
-        "tool",
-        "bot",
-        "cli",
-        "python script",
-        "python program",
-    ]
-
-    if any(kw in lower for kw in verb_keywords):
-        return True
-
-    if "python" in lower and any(obj in lower for obj in object_keywords):
-        return True
-
-    return False
-
-
-def _looks_like_web_search(text: str) -> bool:
-    t = _strip_repl_prefix(text).strip().lower()
-    return t.startswith("web:") or t.startswith("search:")
-
-
-def _extract_web_query(text: str) -> str:
-    t = _strip_repl_prefix(text).strip()
-    lower = t.lower()
-    if lower.startswith("web:"):
-        return t.split(":", 1)[1].strip()
-    if lower.startswith("search:"):
-        return t.split(":", 1)[1].strip()
-    return t
-
-
-def _looks_like_repo_research(text: str) -> bool:
-    t = _strip_repl_prefix(text).strip().lower()
-    return t.startswith("research:") or t.startswith("reindex:")
-
-
-def _extract_repo_research_query(text: str) -> str:
-    # Keep the prefix for research_node to parse reindex:/research:
-    return _strip_repl_prefix(text).strip()
-
-
 def intent_router_node(state: LlamiaState) -> LlamiaState:
     state.log(f"[{NODE_NAME}] starting")
 
     # Always ensure trace is a list
     try:
         state.trace = list(getattr(state, "trace", []) or [])
     except Exception:
         state.trace = []
 
     def _trace(event: str, **kw: Any) -> None:
         # Keep trace as structured dicts (graph.py wraps a separate string trace line too)
         state.trace.append(
             {
                 "node": NODE_NAME,
                 "event": event,
                 "turn_id": getattr(state, "turn_id", None),
                 "ts": time.time(),
                 **kw,
             }
         )
 
     # If no messages, start in chat
     if not getattr(state, "messages", None):
         state.mode = "chat"
         state.goal = None
+        state.intent_kind = "chat"
+        state.intent_payload = None
+        state.intent_source = "empty"
         state.research_query = None
         state.research_notes = None
         state.web_results = None
         state.web_queue = []
         state.web_search_count = 0
+        state.return_after_web = "chat"
+        state.return_after_research = "chat"
         state.loop_count = 0
         state.fix_instructions = None
         state.next_agent = "chat"
         state.log(f"[{NODE_NAME}] no messages -> chat")
         _trace("route", kind="chat", next_agent="chat")
         return state
 
     last = state.messages[-1]
 
     # If last message is not user, this is usually an internal retry cycle.
     if not isinstance(last, dict) or last.get("role") != "user":
         # Contract-violation repair path: keep the task alive.
         if state.mode == "task" and state.goal and (state.fix_instructions or "").strip():
             # If something upstream already selected a retry target, honor it.
             if state.next_agent not in {"planner", "coder", "research", "research_web", "chat"}:
                 # Default for repair is coder (it must regenerate artifacts)
                 state.next_agent = "coder"
             state.log(f"[{NODE_NAME}] TASK(retry): next_agent={state.next_agent}")
             _trace("route", kind="task_retry", next_agent=state.next_agent)
             return state
 
         state.next_agent = "chat"
         state.log(f"[{NODE_NAME}] last not user -> chat")
         _trace("route", kind="chat", next_agent="chat")
         return state
 
-    text = _strip_repl_prefix(str(last.get("content", "") or ""))
-    lower = text.lower().strip()
+    intent = getattr(state, "intent_kind", None)
+    payload = getattr(state, "intent_payload", None)
 
     # 0) Explicit web search (highest priority)
-    if _looks_like_web_search(text):
-        q = _extract_web_query(text)
+    if intent == "research_web":
+        q = str(payload or "").strip()
+        if not q:
+            q = str(last.get("content", "") or "").strip()
         state.mode = "chat"
         state.goal = None
         state.research_query = q
         state.research_notes = None
         state.web_results = None
         state.web_queue = []
         state.web_search_count = 0
+        state.return_after_web = "chat"
+        state.return_after_research = "chat"
         state.fix_instructions = None
         state.next_agent = "research_web"
         state.log(f"[{NODE_NAME}] WEB: next_agent=research_web query={q!r}")
         _trace("route", kind="web", query=q, next_agent="research_web")
         return state
 
     # 0.5) Explicit repo research (RAG)
-    if _looks_like_repo_research(text):
-        q = _extract_repo_research_query(text)
+    if intent == "research":
+        q = str(payload or "").strip()
+        if not q:
+            q = str(last.get("content", "") or "").strip()
         state.mode = "chat"
         state.goal = None
         state.research_query = q
         state.research_notes = None
         state.web_results = None
         state.web_queue = []
         state.web_search_count = 0
+        state.return_after_web = "chat"
+        state.return_after_research = "chat"
         state.loop_count = 0
         state.fix_instructions = None
         state.next_agent = "research"
         state.log(f"[{NODE_NAME}] RESEARCH: next_agent=research query={q!r}")
         _trace("route", kind="research", query=q, next_agent="research")
         return state
 
     # Clear any old research query when not doing web/research
     state.research_query = None
 
     # 1) Explicit task
-    if lower.startswith("task:") or lower.startswith("task "):
-        goal = _extract_task_goal(text)
+    if intent == "task":
+        goal = str(payload or "").strip() or "(unspecified task goal)"
         state.mode = "task"
         state.goal = goal
         state.research_notes = None
         state.web_results = None
         state.web_queue = []
         state.web_search_count = 0
+        state.return_after_web = "planner"
+        state.return_after_research = "planner"
         state.loop_count = 0
         state.fix_instructions = None
         state.next_agent = "planner"
         state.log(f"[{NODE_NAME}] TASK: mode=task goal={goal!r}")
         _trace("route", kind="task", goal=goal, next_agent="planner")
         return state
 
-    # 2) Heuristic task
-    if _looks_like_task(text):
-        state.mode = "task"
-        state.goal = text
-        state.research_notes = None
-        state.web_results = None
-        state.web_queue = []
-        state.web_search_count = 0
-        state.loop_count = 0
-        state.fix_instructions = None
-        state.next_agent = "planner"
-        state.log(f"[{NODE_NAME}] TASK(heur): mode=task goal={text!r}")
-        _trace("route", kind="task_heur", goal=text, next_agent="planner")
-        return state
-
     # 3) Default chat
     state.mode = "chat"
     state.goal = None
     state.research_notes = None
     state.web_results = None
     state.web_queue = []
     state.web_search_count = 0
+    state.return_after_web = "chat"
+    state.return_after_research = "chat"
     state.loop_count = 0
     state.fix_instructions = None
     state.next_agent = "chat"
     state.log(f"[{NODE_NAME}] CHAT: next_agent=chat")
     _trace("route", kind="chat", next_agent="chat")
     return state
diff --git a/llamia_v3_2/nodes/planner.py b/llamia_v3_2/nodes/planner.py
index 9c2768f5a12e39cb683c6c9fc438090653e26dc4..91441f7d1db0e7f6d53616c864258a0c47933935 100644
--- a/llamia_v3_2/nodes/planner.py
+++ b/llamia_v3_2/nodes/planner.py
@@ -183,50 +183,51 @@ def _enhance_plan_with_context(plan_steps: list[dict], goal: str, research_notes
         
         # Create PlanStep with only the original expected fields
         enhanced_steps.append(PlanStep(
             id=sid, 
             description=desc, 
             status="pending"
         ))
     
     return enhanced_steps
 
 
 def planner_node(state: LlamiaState) -> LlamiaState:
     state.log(f"[{NODE_NAME}] starting")
 
     if state.mode != "task" or not state.goal:
         state.log(f"[{NODE_NAME}] no goal in task mode; nothing to plan")
         return state
 
     # Check if web search is needed before planning
     if (
         DEFAULT_CONFIG.web_search_provider == "searxng"
         and not (state.research_notes or "").strip()
         and _needs_web_search(state.goal)
     ):
         state.research_query = state.goal.strip()
+        state.return_after_web = "planner"
         state.next_agent = "research_web"
         state.add_message(
             "system",
             f"[planner] requesting web search for goal: {state.research_query!r}",
             node=NODE_NAME,
         )
         state.log(f"[{NODE_NAME}] routed to research_web query={state.research_query!r}")
         return state
 
     # Prepare context for planning
     notes = (state.research_notes or "").strip()
     notes_block = f"\n\nWeb research notes:\n{notes}\n" if notes else ""
     
     # Add context about current directory/file context if available
     context_block = ""
     if hasattr(state, 'current_file') and state.current_file:
         context_block += f"\nCurrent file context: {state.current_file}\n"
     if hasattr(state, 'working_dir') and state.working_dir:
         context_block += f"Current working directory: {state.working_dir}\n"
 
     # Determine planning strategy based on goal complexity
     complexity = _analyze_goal_complexity(state.goal)
     
     # Customize prompt based on complexity
     prompt = PLANNER_SYSTEM_PROMPT
@@ -276,26 +277,26 @@ def planner_node(state: LlamiaState) -> LlamiaState:
 
     except Exception as e:
         state.log(f"[{NODE_NAME}] ERROR parsing plan JSON: {e!r}")
         # Fallback: create a simple plan
         plan_steps = [
             PlanStep(
                 id=1, 
                 description=f"Analyze and execute the goal: {state.goal}", 
                 status="pending"
             )
         ]
 
     state.plan = plan_steps
     state.next_agent = None  # Reset routing - let execution flow naturally
     state.log(f"[{NODE_NAME}] created {len(plan_steps)} plan steps: {[step.description for step in plan_steps]}")
     
     # Add plan summary to messages for context
     if plan_steps:
         plan_summary = "\n".join([f"Step {step.id}: {step.description}" for step in plan_steps])
         state.add_message(
             "system",
             f"Generated execution plan:\n{plan_summary}",
             node=NODE_NAME,
         )
 
-    return state
\ No newline at end of file
+    return state
diff --git a/llamia_v3_2/nodes/research.py b/llamia_v3_2/nodes/research.py
index 057452d24e79d11369a69c92e73f24e6a1b824c3..92a931382ac7cf29baa04563207c735657e14b50 100644
--- a/llamia_v3_2/nodes/research.py
+++ b/llamia_v3_2/nodes/research.py
@@ -25,27 +25,31 @@ def research_node(state: LlamiaState) -> LlamiaState:
     # Allow explicit reindex
     force = False
     q = (state.research_query or user_text).strip()
 
     low = q.lower()
     if low.startswith("reindex:"):
         force = True
         q = q.split(":", 1)[1].strip()
     elif low.startswith("research:"):
         q = q.split(":", 1)[1].strip()
 
     # (Re)ingest repo
     ingested = ingest_repo(force=force)
     state.log(f"[{NODE_NAME}] ingested_docs={ingested} force={force}")
 
     # Query
     answer = query_repo(query=q, top_k=DEFAULT_CONFIG.rag_top_k)
     state.research_notes = answer
 
     state.add_message(
         role="system",
         content=f"[research results]\nQuery: {q}\n\n{answer}",
         node=NODE_NAME,
     )
 
+    target = str(getattr(state, "return_after_research", "") or "").strip()
+    if target not in {"planner", "coder", "chat", "research"}:
+        target = "planner" if state.mode == "task" else "chat"
+    state.next_agent = target
     state.log(f"[{NODE_NAME}] done")
     return state
diff --git a/llamia_v3_2/nodes/research_web.py b/llamia_v3_2/nodes/research_web.py
index 3c27f70ae34a287b14ff3027f1965e490fbe8ac2..ede12f2484ef06be54368480064add415a5b3ec8 100644
--- a/llamia_v3_2/nodes/research_web.py
+++ b/llamia_v3_2/nodes/research_web.py
@@ -1,66 +1,96 @@
 from __future__ import annotations
 
 import httpx
 
 from ..state import LlamiaState
 from ..config import DEFAULT_CONFIG
 
 NODE_NAME = "research_web"
 
 
+def _resolve_return_after_web(state: LlamiaState) -> str:
+    target = str(getattr(state, "return_after_web", "") or "").strip()
+    if target in {"planner", "coder", "chat", "research_web"}:
+        return target
+    return "planner" if state.mode == "task" else "chat"
+
+
+def _pop_web_queue(state: LlamiaState) -> str | None:
+    queue = getattr(state, "web_queue", None)
+    if not isinstance(queue, list) or not queue:
+        return None
+    while queue:
+        q = str(queue.pop(0)).strip()
+        if q:
+            return q
+    return None
+
+
 def research_web_node(state: LlamiaState) -> LlamiaState:
     state.log(f"[{NODE_NAME}] starting")
 
     query = (state.research_query or "").strip()
+    if not query:
+        queued = _pop_web_queue(state)
+        if queued:
+            query = queued
+            state.research_query = query
+
     if not query:
         state.log(f"[{NODE_NAME}] no research_query; skipping")
-        state.next_agent = "planner" if state.mode == "task" else "chat"
+        state.next_agent = _resolve_return_after_web(state)
         return state
 
     if DEFAULT_CONFIG.web_search_provider != "searxng":
         state.add_message("system", "[web_search] disabled in config.", node=NODE_NAME)
         state.research_query = None
-        state.next_agent = "planner" if state.mode == "task" else "chat"
+        state.next_agent = _resolve_return_after_web(state)
         return state
 
     # only emit marker if we really have a query
     state.add_message(
         "system",
         f"[web_search] provider=searxng url={DEFAULT_CONFIG.searxng_url!r} query={query!r}",
         node=NODE_NAME,
     )
 
     url = DEFAULT_CONFIG.searxng_url.rstrip("/") + "/search"
     params = {"q": query, "format": "json"}
 
     try:
         with httpx.Client(timeout=DEFAULT_CONFIG.web_search_timeout_s) as client:
             r = client.get(url, params=params)
             r.raise_for_status()
             data = r.json()
     except Exception as e:
         state.add_message("system", f"[web_search] ERROR: {e!r}", node=NODE_NAME)
         state.log(f"[{NODE_NAME}] error={e!r}")
         state.research_query = None
-        state.next_agent = "planner" if state.mode == "task" else "chat"
+        state.next_agent = _resolve_return_after_web(state)
         return state
 
     results = (data.get("results") or [])[: max(1, int(DEFAULT_CONFIG.web_search_top_k))]
 
     lines = [f"[web_search results] top_k={len(results)} query={query!r}"]
     for i, item in enumerate(results, 1):
         title = (item.get("title") or "").strip()
         link = (item.get("url") or "").strip()
         snippet = (item.get("content") or "").strip()
         lines.append(f"{i}. {title}\n   {link}\n   {snippet}")
 
     notes = "\n".join(lines)
     state.research_notes = notes
     state.add_message("system", notes, node=NODE_NAME)
 
+    next_query = _pop_web_queue(state)
+    if next_query:
+        state.research_query = next_query
+        state.next_agent = "research_web"
+        state.log(f"[{NODE_NAME}] queued next_query; looping to research_web")
+        return state
+
     state.research_query = None
-    state.next_agent = "planner" if state.mode == "task" else "chat"
+    state.next_agent = _resolve_return_after_web(state)
     state.log(f"[{NODE_NAME}] got_results={len(results)} next_agent={state.next_agent}")
     return state
 
-
diff --git a/llamia_v3_2/repl/app.py b/llamia_v3_2/repl/app.py
index 5125f325702b116a7106554d10542674906a1e44..fefac9cf4653b77151b1e9d736cf61ae538ebe18 100644
--- a/llamia_v3_2/repl/app.py
+++ b/llamia_v3_2/repl/app.py
@@ -2,67 +2,79 @@ from __future__ import annotations
 
 from collections import Counter
 import sys
 import time
 from pathlib import Path
 from typing import Any, Optional
 
 from llamia_v3_2.graph import build_llamia_graph
 from llamia_v3_2.state import LlamiaState
 
 from .config import ReplConfig
 from .contract import validate_task_contract
 from .input_utils import read_user_input_block
 from .logging_utils import append_jsonl, read_if_exists, setup_run_logger
 from .paths import RepoPaths
 from .repo_utils import dirty_outside_workspace, git_ls_files, git_restore_paths, repo_snapshot_text
 from .state_utils import coerce_to_state, state_snapshot
 from .timeouts import InvokeTimeout, invoke_timeout
 
 
 def _reset_turn_fields(state: LlamiaState) -> None:
     """
     Normalize/reset per-turn fields to a known state.
     """
     state.responded_turn_id = -1
+    state.intent_kind = None
+    state.intent_payload = None
+    state.intent_source = None
     state.web_search_count = 0
     state.web_results = None
     state.research_query = None
     state.research_notes = None
     state.web_queue = []
     state.return_after_web = "planner"
+    state.return_after_research = "planner"
     state.loop_count = 0
 
 
 def _ensure_turn_fields_exist(state: LlamiaState) -> None:
     """
     Backward compatibility: older LlamiaState versions may not have turn_id fields.
     """
     if not hasattr(state, "turn_id"):
         state.turn_id = 0
     if not hasattr(state, "responded_turn_id"):
         state.responded_turn_id = -1
+    if not hasattr(state, "intent_kind"):
+        state.intent_kind = None
+    if not hasattr(state, "intent_payload"):
+        state.intent_payload = None
+    if not hasattr(state, "intent_source"):
+        state.intent_source = None
+    if not hasattr(state, "return_after_research"):
+        state.return_after_research = "planner"
 
 
 def run_repl(config: Optional[ReplConfig] = None) -> int:
     """
     Main interactive loop.
     Returns a process exit code (0 for normal exit).
     """
     cfg = config or ReplConfig()
 
     # __file__ is .../llamia_v3_2/repl/app.py
     # parents[2] is repo root (because: repl -> llamia_v3_2 -> repo_root)
     entry_main = Path(__file__).resolve().parents[2] / "main.py"
     paths = RepoPaths.from_entrypoint(entry_main)
 
     logger, _text_path, jsonl_path = setup_run_logger(paths)
 
     state = LlamiaState()
     _ensure_turn_fields_exist(state)
 
     app = build_llamia_graph()
 
     print("Llamia v3.2 (LangGraph + planner + coder + executor + chat). Type 'exit' to quit.\n")
     print("Tips:")
     print("  - Normal message: regular chat mode")
     print("  - 'task: build me X': task mode => planner, coder (writes into workspace/), executor (runs safe commands), then chat.\n")
diff --git a/llamia_v3_2/repl/state_utils.py b/llamia_v3_2/repl/state_utils.py
index 7e4853df249659ff4dbc7d596679af1a24482032..23a1bb76b9660ce31ffaf54f54de66ab7386d160 100644
--- a/llamia_v3_2/repl/state_utils.py
+++ b/llamia_v3_2/repl/state_utils.py
@@ -19,50 +19,53 @@ def state_snapshot(state: LlamiaState) -> Dict[str, Any]:
     """
     msgs: list[dict[str, Any]] = []
     for m in (state.messages or [])[-12:]:
         msgs.append(
             {
                 "role": m.get("role"),
                 "node": m.get("node"),
                 "content": tail_lines((m.get("content") or "").strip(), max_chars=2000),
             }
         )
 
     last_exec: list[dict[str, Any]] = []
     for r in (getattr(state, "last_exec_results", None) or [])[-6:]:
         last_exec.append(
             {
                 "command": r.command,
                 "returncode": r.returncode,
                 "stdout_tail": tail_lines((r.stdout or "").strip(), max_chars=1500),
                 "stderr_tail": tail_lines((r.stderr or "").strip(), max_chars=1500),
             }
         )
 
     return {
         "mode": getattr(state, "mode", None),
         "goal": getattr(state, "goal", None),
+        "intent_kind": getattr(state, "intent_kind", None),
+        "intent_payload": getattr(state, "intent_payload", None),
+        "intent_source": getattr(state, "intent_source", None),
         "next_agent": getattr(state, "next_agent", None),
         "loop_count": getattr(state, "loop_count", None),
         "web_search_count": getattr(state, "web_search_count", None),
         "research_query": getattr(state, "research_query", None),
         "trace": getattr(state, "trace", None),
         "messages_tail": msgs,
         "exec_request": getattr(state, "exec_request", None),
         "last_exec_results_tail": last_exec,
     }
 
 
 def make_exec_results(raw_list: Any) -> List[ExecResult]:
     """
     Normalize an untyped list of exec results into `list[ExecResult]`.
     """
     results: list[ExecResult] = []
     if not isinstance(raw_list, list):
         return results
 
     for r in raw_list:
         if isinstance(r, ExecResult):
             results.append(r)
             continue
 
         if isinstance(r, dict):
@@ -124,58 +127,63 @@ def coerce_to_state(raw: Any) -> LlamiaState:
         applied_patches = _make_patches(raw.get("applied_patches") or [])
 
         raw_exec = raw.get("exec_request")
         exec_req: ExecRequest | None = None
         if isinstance(raw_exec, ExecRequest):
             exec_req = raw_exec
         elif isinstance(raw_exec, dict):
             workdir = str(raw_exec.get("workdir", "workspace")).strip() or "workspace"
             commands = raw_exec.get("commands") or []
             if isinstance(commands, list):
                 commands = [str(c).strip() for c in commands if str(c).strip()]
             else:
                 commands = []
             if commands:
                 exec_req = ExecRequest(workdir=workdir, commands=commands)
 
         exec_results = make_exec_results(raw.get("exec_results") or [])
         last_exec_results = make_exec_results(raw.get("last_exec_results") or [])
 
         web_queue = raw.get("web_queue") or []
         if not isinstance(web_queue, list):
             web_queue = []
         web_queue = [str(q).strip() for q in web_queue if str(q).strip()]
 
         return_after_web = str(raw.get("return_after_web", "planner") or "planner").strip() or "planner"
+        return_after_research = str(raw.get("return_after_research", "planner") or "planner").strip() or "planner"
 
         turn_id = int(raw.get("turn_id", 0) or 0)
         responded_turn_id = int(raw.get("responded_turn_id", -1) or -1)
 
         return LlamiaState(
             messages=raw.get("messages", []),
             mode=raw.get("mode", "chat"),
             goal=raw.get("goal"),
             plan=plan,
             pending_patches=pending_patches,
             applied_patches=applied_patches,
             exec_request=exec_req,
             exec_results=exec_results,
             last_exec_results=last_exec_results,
             next_agent=raw.get("next_agent"),
             trace=raw.get("trace", []),
             research_query=raw.get("research_query"),
             research_notes=raw.get("research_notes"),
             fix_instructions=raw.get("fix_instructions"),
             loop_count=int(raw.get("loop_count", 0) or 0),
             expected_failure=bool(raw.get("expected_failure", False)),
             web_queue=web_queue,
             web_results=raw.get("web_results"),
             return_after_web=return_after_web,
+            return_after_research=return_after_research,
             web_search_count=int(raw.get("web_search_count", 0) or 0),
+            intent_kind=raw.get("intent_kind"),
+            intent_payload=raw.get("intent_payload"),
+            intent_source=raw.get("intent_source"),
             turn_id=turn_id,
             responded_turn_id=responded_turn_id,
         )
 
     # Worst-case fallback: preserve REPL stability.
     state = LlamiaState()
     state.log(f"[repl] WARNING: unexpected state type from graph: {type(raw)!r}")
     return state
diff --git a/llamia_v3_2/state.py b/llamia_v3_2/state.py
index fe47ff3ae7d47e6223c957b8a9fedd070c232e07..a2986570e4073ae54d4dd016f816a3029766aa22 100644
--- a/llamia_v3_2/state.py
+++ b/llamia_v3_2/state.py
@@ -34,65 +34,71 @@ class ExecRequest:
 class ExecResult:
     command: str
     returncode: int
     stdout: str
     stderr: str
 
 
 @dataclass
 class LlamiaState:
     """
     Core shared state for Llamia v3.2.
 
     This state is intentionally "plain" so LangGraph can serialize it to dicts and back.
     """
     messages: list[Message] = field(default_factory=list)
 
 
     turn_id: int = 0
     responded_turn_id: int = -1
     
     
     # High-level mode
     mode: Literal["chat", "task"] = "chat"
     goal: str | None = None
 
+    # Intent classification (set by intent_classifier, consumed by intent_router)
+    intent_kind: Literal["chat", "task", "research", "research_web"] | None = None
+    intent_payload: str | None = None
+    intent_source: str | None = None
+
     # Task plan
     plan: list[PlanStep] = field(default_factory=list)
 
     # Code patches
     pending_patches: list[CodePatch] = field(default_factory=list)
     applied_patches: list[CodePatch] = field(default_factory=list)
 
     # Local research / RAG
     research_query: str | None = None
     research_notes: str | None = None
 
     # Web search / research_web node
     web_queue: list[str] = field(default_factory=list)   # pending web queries
     web_results: str | None = None                       # last web results summary
     return_after_web: str = "planner"                    # where to go when web finishes
+    return_after_research: str = "planner"               # where to go when repo research finishes
 
 
     # Critic web-search throttle (resets per task)
     web_search_count: int = 0
 
     # Execution request (suggested commands)
     exec_request: ExecRequest | None = None
 
     # Full history of execution results (across loops)
     exec_results: list[ExecResult] = field(default_factory=list)
 
     # Latest execution results (from the most recent executor run only)
     last_exec_results: list[ExecResult] = field(default_factory=list)
 
     # Routing / control
     next_agent: str | None = None
     loop_count: int = 0
 
     # Critic -> Coder guidance
     fix_instructions: str | None = None
 
     # If task is intentionally demonstrating a failure (dont auto-fix)
     expected_failure: bool = False
 
     # Debugging trace
diff --git a/llamia_v3_2/state_improved.py b/llamia_v3_2/state_improved.py
index 58aa07d664364cbf99995a61d93a394204c6747b..1b9ba5d4c8d6678505e64b8450fa65579b7961dd 100644
--- a/llamia_v3_2/state_improved.py
+++ b/llamia_v3_2/state_improved.py
@@ -43,65 +43,71 @@ class ExecRequest:
 class ExecResult:
     command: str
     returncode: int
     stdout: str
     stderr: str
 
 
 @dataclass
 class LlamiaState:
     """
     Core shared state for Llamia v3.2.
 
     This state is intentionally "plain" so LangGraph can serialize it to dicts and back.
     """
     messages: list[Message] = field(default_factory=list)
 
 
     turn_id: int = 0
     responded_turn_id: int = -1
     
     
     # High-level mode
     mode: Literal["chat", "task"] = "chat"
     goal: str | None = None
 
+    # Intent classification (set by intent_classifier, consumed by intent_router)
+    intent_kind: Literal["chat", "task", "research", "research_web"] | None = None
+    intent_payload: str | None = None
+    intent_source: str | None = None
+
     # Task plan
     plan: list[PlanStep] = field(default_factory=list)
 
     # Code patches
     pending_patches: list[CodePatch] = field(default_factory=list)
     applied_patches: list[CodePatch] = field(default_factory=list)
 
     # Local research / RAG
     research_query: str | None = None
     research_notes: str | None = None
 
     # Web search / research_web node
     web_queue: list[str] = field(default_factory=list)   # pending web queries
     web_results: str | None = None                       # last web results summary
     return_after_web: str = "planner"                    # where to go when web finishes
+    return_after_research: str = "planner"               # where to go when repo research finishes
 
 
     # Critic web-search throttle (resets per task)
     web_search_count: int = 0
 
     # Execution request (suggested commands)
     exec_request: ExecRequest | None = None
 
     # Full history of execution results (across loops)
     exec_results: list[ExecResult] = field(default_factory=list)
 
     # Latest execution results (from the most recent executor run only)
     last_exec_results: list[ExecResult] = field(default_factory=list)
 
     # Routing / control
     next_agent: str | None = None
     loop_count: int = 0
 
     # Critic -> Coder guidance
     fix_instructions: str | None = None
 
     # If task is intentionally demonstrating a failure (dont auto-fix)
     expected_failure: bool = False
 
     # Debugging trace
diff --git a/tests/test_improved_graph_routing.py b/tests/test_improved_graph_routing.py
index 710d21966bf833baf04e54776e4fa1e78587dc75..0eedec7ffee6496119286b75487229d7e0984a62 100644
--- a/tests/test_improved_graph_routing.py
+++ b/tests/test_improved_graph_routing.py
@@ -22,48 +22,48 @@ def test_routing_error_handling():
             _route_from_critic
         )
         
         # Test routing with None state (should not crash)
         result = _route_from_intent(None)
         assert result == "chat", f"Expected 'chat' but got {result}"
         print("? Intent router handles None state correctly")
         
         # Test routing with empty dict state
         result = _route_from_intent({})
         assert result == "chat", f"Expected 'chat' but got {result}"
         print("? Intent router handles empty dict correctly")
         
         # Test planner routing with None state
         result = _route_from_planner(None)
         assert result == "coder", f"Expected 'coder' but got {result}"
         print("? Planner router handles None state correctly")
         
         # Test research routing with None state
         result = _route_from_research(None)
         assert result == "chat", f"Expected 'chat' but got {result}"
         print("? Research router handles None state correctly")
         
         # Test research_web routing with None state
         result = _route_from_research_web(None)
-        assert result == "executor", f"Expected 'executor' but got {result}"
+        assert result == "chat", f"Expected 'chat' but got {result}"
         print("? Research web router handles None state correctly")
         
         # Test coder routing with None state
         result = _route_from_coder(None)
         assert result == "executor", f"Expected 'executor' but got {result}"
         print("? Coder router handles None state correctly")
         
         # Test critic routing with None state
         result = _route_from_critic(None)
         assert result == "chat", f"Expected 'chat' but got {result}"
         print("? Critic router handles None state correctly")
         
         return True
     except Exception as e:
         print(f"? Routing error handling test failed: {e}")
         import traceback
         traceback.print_exc()
         return False
 
 if __name__ == "__main__":
     success = test_routing_error_handling()
     sys.exit(0 if success else 1)
